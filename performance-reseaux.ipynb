{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "72212eb2",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "L'entraînement des réseaux de neurones est long, ce qui m'a amené à chercher pourquoi ils sont aussi longs (et à les améliorer en conséquence). Je me suis aperçu que la lenteur principale venait de l'itération des données et donc de pytorch (des dataloaders) à cause de la grande quantité de données que j'avais (plus ou moins 10 millions). Il y a une première partie sur la lenteur de la libarrie plyfile, une autre partie sur les dataloaders et enfin une partie sur le parallélisme avec torch.multiprocessing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4648c98",
   "metadata": {},
   "source": [
    "# Lecture fichier ply\n",
    "\n",
    "temps : python > np.loadtxt > plyfile\n",
    "\n",
    "memoire : np.loadtxt > plyfile > python\n",
    "\n",
    "Donc on utilisera seulement plyfile pour écrire des fichiers .ply puisqu'il se trouve qu'il n'est pas adapté pour lire nos fichiers ply (on lit que les 3 premières colonnes),ce qui donne un temps de lecture très lent par fichier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9af4202e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-16T08:31:35.917063Z",
     "iopub.status.busy": "2023-08-16T08:31:35.915604Z",
     "iopub.status.idle": "2023-08-16T08:31:51.408142Z",
     "shell.execute_reply": "2023-08-16T08:31:51.406371Z",
     "shell.execute_reply.started": "2023-08-16T08:31:35.917007Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting plyfile\n",
      "  Downloading plyfile-1.0.1-py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from plyfile) (1.23.5)\n",
      "Installing collected packages: plyfile\n",
      "Successfully installed plyfile-1.0.1\n"
     ]
    }
   ],
   "source": [
    "!pip install plyfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c423643",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-16T08:31:51.411600Z",
     "iopub.status.busy": "2023-08-16T08:31:51.411068Z",
     "iopub.status.idle": "2023-08-16T08:31:52.246477Z",
     "shell.execute_reply": "2023-08-16T08:31:52.245579Z",
     "shell.execute_reply.started": "2023-08-16T08:31:51.411549Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7907719612121582\n",
      "0.02049088478088379\n"
     ]
    }
   ],
   "source": [
    "from plyfile import PlyData, PlyElement\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "with open('/kaggle/input/abc-dataset-train/'+'0002.ply', 'rb') as f:\n",
    "    st = time.time()\n",
    "    plydata = PlyData.read(f)\n",
    "    et = time.time()-st\n",
    "    print(et)\n",
    "    \n",
    "with open('/kaggle/input/abc-dataset-train/'+'0002.ply', 'r') as f:    \n",
    "    \n",
    "    st = time.time()\n",
    "    while \"end_header\" not in f.readline():\n",
    "        pass      \n",
    "    np.loadtxt(f, dtype=np.float32, ndmin=2, usecols=(0, 1, 2))\n",
    "    et = time.time()-st\n",
    "    print(et)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26025ace",
   "metadata": {},
   "source": [
    "# Dataset\n",
    "\n",
    "Définissons un dataset similaire à celui utilisé dans le notebook \"reseau_simple\", qui occupe environ 0,3go en mémoire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f354cf4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-16T08:31:52.248482Z",
     "iopub.status.busy": "2023-08-16T08:31:52.248091Z",
     "iopub.status.idle": "2023-08-16T08:31:54.133499Z",
     "shell.execute_reply": "2023-08-16T08:31:54.132263Z",
     "shell.execute_reply.started": "2023-08-16T08:31:52.248414Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "59996618",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-16T08:31:54.137962Z",
     "iopub.status.busy": "2023-08-16T08:31:54.137102Z",
     "iopub.status.idle": "2023-08-16T08:31:56.139674Z",
     "shell.execute_reply": "2023-08-16T08:31:56.138400Z",
     "shell.execute_reply.started": "2023-08-16T08:31:54.137910Z"
    }
   },
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data, labels):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.data[idx],self.labels[idx]\n",
    "        return sample\n",
    "\n",
    "\n",
    "n=5000000\n",
    "data = torch.randn(n, 33)  \n",
    "labels = torch.randint(0, 1, (n,))  \n",
    "\n",
    "custom_dataset = CustomDataset(data, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65d40d1f",
   "metadata": {},
   "source": [
    "# Dataloader\n",
    "\n",
    "Définissons un dataloader sur ce dataset. On utilisera la librarie tqdm pour avoir le temps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dfe5b94f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-16T08:31:56.141989Z",
     "iopub.status.busy": "2023-08-16T08:31:56.141498Z",
     "iopub.status.idle": "2023-08-16T08:32:28.548409Z",
     "shell.execute_reply": "2023-08-16T08:32:28.546993Z",
     "shell.execute_reply.started": "2023-08-16T08:31:56.141943Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50000/50000 [00:32<00:00, 1543.59it/s]\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "batch_size = 100\n",
    "dataloader = DataLoader(custom_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "for inputs, labels in tqdm(dataloader):\n",
    "    pass         "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdf86015",
   "metadata": {},
   "source": [
    "32s pour parcourir 0,3go est long, puisque je rappelle que les données sont sur la ram et que même si c'était sur mon disque dur il fait facilement du 0,3go minimum à la lecture ou en écriture. On en déduit que ce n'est pas une limite sur les E/S (et on peut le constater par exemple en utilisant iostat pour voir l'utilisation du disque dur).\n",
    "\n",
    "La limite provient de la vitesse d'un seul CPU puisque les autres ne sont pas utilisés. \n",
    "\n",
    "Par la suite on va essayer de réduire ces 32s en jouant sur les différents paramètres offerts par le dataloader qui devraient utiliser le reste des CPUs disponibles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "62f8be54",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-16T08:32:28.551089Z",
     "iopub.status.busy": "2023-08-16T08:32:28.550571Z",
     "iopub.status.idle": "2023-08-16T08:32:28.558250Z",
     "shell.execute_reply": "2023-08-16T08:32:28.556862Z",
     "shell.execute_reply.started": "2023-08-16T08:32:28.551028Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "import torch.multiprocessing as mp\n",
    "\n",
    "print(mp.cpu_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "26c1bfd7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-16T08:32:28.560609Z",
     "iopub.status.busy": "2023-08-16T08:32:28.560130Z",
     "iopub.status.idle": "2023-08-16T08:34:22.151655Z",
     "shell.execute_reply": "2023-08-16T08:34:22.149934Z",
     "shell.execute_reply.started": "2023-08-16T08:32:28.560564Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50000/50000 [01:53<00:00, 440.25it/s]\n"
     ]
    }
   ],
   "source": [
    "batch_size = 100\n",
    "dataloader = DataLoader(custom_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "for inputs, labels in tqdm(dataloader):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aa27fdd",
   "metadata": {},
   "source": [
    "Ce qui est étonant c'est que c'est moins performant, alors que num_workers=2 permet de dédier 2 cpus au chargement des données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0ab27c6e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-16T08:34:22.154352Z",
     "iopub.status.busy": "2023-08-16T08:34:22.153961Z",
     "iopub.status.idle": "2023-08-16T08:36:39.040413Z",
     "shell.execute_reply": "2023-08-16T08:36:39.038929Z",
     "shell.execute_reply.started": "2023-08-16T08:34:22.154317Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50000/50000 [02:16<00:00, 365.30it/s]\n"
     ]
    }
   ],
   "source": [
    "batch_size = 100\n",
    "dataloader = DataLoader(custom_dataset, batch_size=batch_size, shuffle=False, num_workers=2, prefetch_factor=100)\n",
    "\n",
    "for inputs, labels in tqdm(dataloader):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc52849b",
   "metadata": {},
   "source": [
    "Et en changeant prefetch_factor l'itération devient encore plus lente. Augmenter prefetch_factor permet d'indiquer qu'il faut charger plus de données par CPU (à l'avance)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9788949f",
   "metadata": {},
   "source": [
    "# Dataloader from scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5cb8c7d",
   "metadata": {},
   "source": [
    "Si on regarde le code source de dataloader (https://github.com/pytorch/pytorch/blob/main/torch/utils/data/dataloader.py), on constate que le shuffle se fait grâce à torch.randperm et que le batch se fait de cette manière avec torch.utils.data.default_collate([x for i in batch]). On peut essayer de reproduire le code :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8af45dde",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-16T08:36:39.043862Z",
     "iopub.status.busy": "2023-08-16T08:36:39.043023Z",
     "iopub.status.idle": "2023-08-16T08:37:56.507692Z",
     "shell.execute_reply": "2023-08-16T08:37:56.506408Z",
     "shell.execute_reply.started": "2023-08-16T08:36:39.043808Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50000/50000 [01:17<00:00, 648.61it/s]\n"
     ]
    }
   ],
   "source": [
    "batch_size = 100\n",
    "\n",
    "indices = torch.randperm(len(dataloader.dataset))\n",
    "for i in tqdm(range(0,len(indices),batch_size)):\n",
    "    data = []\n",
    "    targets = []\n",
    "    \n",
    "    for j in range(i,i+batch_size):\n",
    "        if j < len(indices):\n",
    "            data.append(dataloader.dataset.data[indices[j]])\n",
    "            targets.append(dataloader.dataset.labels[indices[j]])\n",
    "            \n",
    "            \n",
    "    data = torch.utils.data.default_collate(data)\n",
    "    targets = torch.utils.data.default_collate(targets)   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b07d700",
   "metadata": {},
   "source": [
    "On obtient des performances assez mauvaises comparés à un dataloader. Donc le problème (la lenteur) doit provenir de l'accès aux éléments du dataset. Ce qui est le cas puisqu'en regardant toujours le lien (qui a été envoyé) on observe cette partie du code :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea1cd1f4",
   "metadata": {},
   "source": [
    "![image.png](a.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6202ad8",
   "metadata": {},
   "source": [
    "data = [self.dataset[idx] for idx in possibly_batched_index]\n",
    "\n",
    "Le dataloaader ne prend pas en compte que les données sont contigues et fera forcément un self.dataset[idx] sur tous les éléments. En reprenant le code d'en-dessous et en supprimant le shuffle on peut arriver à ça : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "28529115",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-16T08:37:56.511570Z",
     "iopub.status.busy": "2023-08-16T08:37:56.511173Z",
     "iopub.status.idle": "2023-08-16T08:37:56.894380Z",
     "shell.execute_reply": "2023-08-16T08:37:56.893497Z",
     "shell.execute_reply.started": "2023-08-16T08:37:56.511537Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50000/50000 [00:00<00:00, 135869.11it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(0,len(dataloader.dataset), batch_size)):\n",
    "    data = dataloader.dataset.data[i*batch_size:(i+1)*batch_size]\n",
    "    targets = dataloader.dataset.labels[i*batch_size:(i+1)*batch_size]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36bc5ce0",
   "metadata": {},
   "source": [
    "Ce qui donne des résultats très intéressants puisque contraitement à un dataloader (avec le shuffle désactivé) il continuera d'accèder au dataset de cette manière self.dataset[idx] ce qui est lent.\n",
    "\n",
    "\n",
    "On pourrait refaire un dataloader en utilisant un accès par \"tranche\" (slicing) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6f4a047f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-16T08:44:51.373660Z",
     "iopub.status.busy": "2023-08-16T08:44:51.373226Z",
     "iopub.status.idle": "2023-08-16T08:44:53.699650Z",
     "shell.execute_reply": "2023-08-16T08:44:53.698547Z",
     "shell.execute_reply.started": "2023-08-16T08:44:51.373625Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50000/50000 [00:01<00:00, 25616.76it/s]\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "    \n",
    "batch_size = 100\n",
    "\n",
    "indices = torch.randperm(len(dataloader.dataset))\n",
    "for i in tqdm(range(0, len(indices), batch_size)):\n",
    "    end_index = min(i + batch_size, len(indices))\n",
    "    batch_indices = indices[i:end_index]\n",
    "\n",
    "    data = dataloader.dataset.data[batch_indices]\n",
    "    targets = dataloader.dataset.labels[batch_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f176490e",
   "metadata": {},
   "source": [
    "Ce qui nous donne de bien meilleurs performances. On passe de 32s à 1s."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c526e76",
   "metadata": {},
   "source": [
    "# ConcatDataset & dataset multiprocessing\n",
    "\n",
    "J'avais fait une version du chargement des données parallélisés en répartissant les fichiers à charger sur différents process. Le chargement des données était plus rapide, mais j'ai remarqué que le dataloader était plus long. Je pensais que c'était peut-être une question de cache donc j'avais fait un dataset avec les données contigues sauf que ça ne changeait rien. Et effectivement c'est bien un problème : https://github.com/pytorch/pytorch/issues/51011 .\n",
    "\n",
    "Le code en-dessous pour la parallélisation des données et pour son utilisation se référer à l'un des 2 notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b61bf9d9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-15T20:56:47.383015Z",
     "iopub.status.busy": "2023-08-15T20:56:47.382591Z",
     "iopub.status.idle": "2023-08-15T20:56:47.398355Z",
     "shell.execute_reply": "2023-08-15T20:56:47.396482Z",
     "shell.execute_reply.started": "2023-08-15T20:56:47.382980Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch.multiprocessing as mp\n",
    "\n",
    "def diviser_liste(liste, nombre):\n",
    "    taille_sous_liste = max(1,len(liste)//nombre)\n",
    "    return [liste[i:i + taille_sous_liste] for i in range(0, len(liste), taille_sous_liste)]\n",
    "\n",
    "\n",
    "def wrapper_charger_datasets(chemin,fichiers, queue):\n",
    "    queue.put(charger_datasets(chemin,fichiers))\n",
    "\n",
    "def parallele_charger_datasets(chemin, fichiers, num_cpus):    \n",
    "    resultat_queue = mp.Manager().Queue()\n",
    "    partage = diviser_liste(fichiers, num_cpus)\n",
    "\n",
    "    processes = []\n",
    "    for sous_liste in partage:\n",
    "        p = mp.Process(target=wrapper_charger_datasets, args=(chemin, sous_liste, resultat_queue))\n",
    "        processes.append(p)\n",
    "        p.start()\n",
    "\n",
    "    for p in processes:\n",
    "        p.join()\n",
    "\n",
    "    list_data = []\n",
    "    list_labels = []\n",
    "    while not resultat_queue.empty():\n",
    "        res = resultat_queue.get()\n",
    "        for (a,b) in res:\n",
    "            list_data.append(a)    \n",
    "            list_labels.append(torch.tensor(b))    \n",
    "    data = torch.cat(list_data, dim=0)\n",
    "    labels = torch.cat(list_labels, dim=0)\n",
    "    concatenated_dataset = SimpleDataset(data,labels)\n",
    "    \n",
    "    return concatenated_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02e75f4c",
   "metadata": {},
   "source": [
    "# Keras/Tensorflow ?\n",
    "\n",
    "Pour avoir refait \"réseau simple\" sous keras/tensorflow j'ai retrouvé le même problème que sur pytorch sur la lenteur des parcours de données, puisqu'on pouvait espèrer que ça aille plus vite car keras/tensorflow utilise des numpy et que les numpy sont plus rapides à parcourir que les tensors. Voir le notebook \"reseau_simple avec keras\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "30a81f58",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-15T20:56:47.402105Z",
     "iopub.status.busy": "2023-08-15T20:56:47.401444Z",
     "iopub.status.idle": "2023-08-15T20:57:12.687766Z",
     "shell.execute_reply": "2023-08-15T20:57:12.686313Z",
     "shell.execute_reply.started": "2023-08-15T20:56:47.402053Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7042860984802246 s\n",
      "22.557496309280396 s\n"
     ]
    }
   ],
   "source": [
    "test = np.zeros(10000000, dtype=np.float32)\n",
    "\n",
    "start_time = time.time()\n",
    "for i in range(10000000):\n",
    "    test[i]\n",
    "print(time.time()-start_time, \"s\")\n",
    "\n",
    "\n",
    "test2 = torch.from_numpy(test)#on obtient la même chose qu'en passant par torch.zeros\n",
    "\n",
    "start_time = time.time()\n",
    "for i in range(10000000):\n",
    "    test2[i]\n",
    "print(time.time()-start_time, \"s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ec72296",
   "metadata": {},
   "source": [
    "On notera aussi une utilisation importance de la mémoire pour créer un itérateur sur un torch : https://github.com/pytorch/pytorch/issues/71266"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3848fc9f",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "L'utilisation d'un dataloader pour le dataset de validation a été suppprimé étant donné sa lenteur, je parcours directement le dataset manuellement. Et pour profiter de la contiguité des données j'ai dû définir mon propre dataloader. \n",
    "\n",
    "Pour ce qui est des chargements des données, j'ai supprimé la parallélisation étant donné le gain peu important comparé aux restes (quelques mins) et des problèmes possibles à cause du contexte jupyter-notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc4412b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
